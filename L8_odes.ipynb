{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt2WH9u/dbxuxuymmDd+KO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdallas1/shared_code/blob/main/L8_odes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jB7_beWc9K1u"
      },
      "outputs": [],
      "source": [
        "!apt install octave"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A brief introduction to differential equations\n",
        "\n",
        "The goal of this section is to introduce differential equations, and understand what it means to solve one. We'll focus on two examples.\n",
        "\n",
        "### First order differential equations\n",
        "\n",
        "Consider the problem of modeling the population of bacteria in a Petri dish. Let $P(t)$ denote the population at time $t\\geq 0$. Observing their growth shows that the rate of change of the population is proportional to the size of the population. In other words,\n",
        "\n",
        "$$ \\dfrac{dP}{dt} \\propto P.$$\n",
        "\n",
        "Thus, there's some positive constant $k$ such that\n",
        "\n",
        "$$ \\dfrac{dP}{dt} = k P(t).$$\n",
        "\n",
        "This is a **first order ordinary differential equation.** It is an equation that relates the first derivative of $P(t)$ to the function $P(t)$ itself. We will often shorten *ordinary differential equation* to *ODE*. In general, a first order differential equation can be written as\n",
        "\n",
        "$$ y'(t) = f(t,y).$$\n",
        "\n",
        "In the special case of modeling bacteria growth, $u(t) = P(t)$, and $f(t,P) = kP$.\n",
        "\n",
        "To solve a first order differential equations means finding a function $y$ such that it's first derivative equals $f(t,y)$.\n",
        "\n",
        "> **Exercise** Show that $P(t) = Ce^{kt}$ solves the first order ODE $P'(t) = kP(t)$, where $C$ is an arbitrary real number.\n",
        "\n",
        "Notice that we have an entire family of solutions: one for each constant $C$. Since $P(0) = C$, the interpretation is that $C$ is the initial population of bacteria. If we want to model the population growth with a known initial population, we could pose the following **initial value problem** (IVP):\n",
        "\n",
        "$$ \\dfrac{dP}{dt} = k P(t),\\hspace{2em} P(0) = P_0.$$\n",
        "\n",
        "You can show that the solution to this IVP is $P(t) = P_0e^{kt}$.\n",
        "\n",
        "\n",
        "### Second order differential equations\n",
        "\n",
        "A **second order ODE** is similar to a first order ODE, except now we have an equation relating the second derivative of a function to lower order derivatives. Our example comes from physics. Newton's second law says that the the acceleratin $a(t)$ of a particle of mass $m$ at time $t$ is the net force acting on the object dividing by the mass. Equivalently,\n",
        "\n",
        "$$ F = ma(t).$$\n",
        "\n",
        "Consider a mass (of mass $m$) on a frictionless surface attached to a spring. Let $x(t)$ denote the displacement of the mass from equilibrium at time $t$. Then the force of the spring on the mass at time $t$ is $-kx(t)$, where $k$ is a positive constant. Further, $a(t) = x''(t)$, so Newton's second law applied to this mass-spring system is\n",
        "\n",
        "$$ x''(t) = -kx(t). $$\n",
        "\n",
        "Since this equation relates the second derivative of $x(t)$ to $x(t)$ itself, this is a second order ODE.\n",
        "\n",
        "> **Exercise** Show that both $x(t) = A\\sin(\\sqrt{k}t)$ and $x(t) = B\\sin(\\sqrt{k}t)$ both solve $x''(t) = -kx(t).$\n",
        "\n"
      ],
      "metadata": {
        "id": "bh9SU3av-MeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Euler Methods\n",
        "\n",
        "The first problem we'll tackle is solving a general first order IVP of the form\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "y'(t) &= f(t,y),\\hspace{0.5em} t\\text{ in } [t_0,T] \\\\\n",
        "y(t_0) &= y_0.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "A problem of this form is called the *Cauchy problem*. It's worth noting the following theorem, which provides sufficient conditions for the Cauchy problem to have a unique solution.\n",
        "\n",
        "> **(Existence and Uniqueness)** Let $f(t,y)$ be continuous with respect to $t$ and $y$. Suppose further that $f$ is Lipschitz with respect to $y$, i.e., for all $y_1$ and $y_2$, there is a constant $L$ such that\n",
        "$$ |f(t,y_1)-f(t,y_2)| \\leq L |y_1-y_2|$$\n",
        "for all $t$ in $[t_0,T]$. Then the Cauchy problem has a unique solution $y(t)$ that is $C^1$ in $[t_0,T]$.\n",
        "\n",
        "There are several ways to derive the family of methods for solving these IVPs known as Euler methods. The fundamental idea is to subdivide the interval $[t_0,T]$ into $N_h$ subintervals of length $h$, where $h=(T-t_0)/N_h$. This parameter $h$ is called the **discretization step** or **time step**. We then approximate the solution $y(t_n)$ at the nodes $t_n = t_0 + nh$, with $n=0,1,...,N_h$, by $u_n$.\n",
        "\n",
        "Recall that, using the forward-difference approximation,\n",
        "\n",
        "$$ y'(t_{n-1}) = \\dfrac{y(t_n)-y(t_{n-1})}{h}+\\mathcal{O}(h).$$\n",
        "\n",
        "Since $y'(t_{n-1}) = f(t_{n-1},y(t_{n-1}))$, we can solve for $y(t_n)$ to obtain\n",
        "\n",
        "$$ y(t_n) = y(t_{n-1}) + hf(t_{n-1},y(t_{n-1}))+\\mathcal{O}(h^2).$$\n",
        "\n",
        "Dropping the higher order error terms $\\mathcal{O}(h^2)$ gives us the approximation\n",
        "\n",
        "$$u_n = y(t_{n-1}) + hf(t_{n-1},y(t_{n-1})).$$\n",
        "\n",
        "Now, we don't know $y(t_{n-1})$, except at $t_0$. So, starting from $n=0$, we can compute\n",
        "\n",
        "$$ u_1 = y_0 + hf(t_0,y_0),$$\n",
        "\n",
        "and then for $n = 1,2,...,N_h-1$,\n",
        "\n",
        "$$ u_{n+1} = u_n + hf(t_n,u_n).$$\n",
        "\n",
        "This is known as the **forward Euler method**.\n",
        "\n",
        "If we back up a few steps, and if instead of the forward-difference approximation we use the backward-difference approximation, we obtain\n",
        "\n",
        "$$ f(t_{n+1},y(t_{n+1})) = y'(t_{n+1}) \\approx \\dfrac{y(t_{n+1})-y(t_{n})}{h}$$\n",
        "\n",
        "Replacing $y(t_{n})$ with $u_{n}$  and $y(t_{n+1})$ with $u_{n+1}$ we obtain\n",
        "\n",
        "$$ u_{n+1} = u_{n} + hf(t_{n+1},u_{n+1})$$\n",
        "\n",
        "for $n=0,...,N_h-1$. This is the **backward Euler method**. The most significant difference between the forward and backward Euler methods is that in the backward Euler method, we have to solve the equation\n",
        "\n",
        "$$ u_{n+1} -u_n -hf(t_{n+1},u_{n+1}) = 0$$\n",
        "\n",
        "for $u_{n+1}$. If $f$ is nonlinear, the ODE is nonlinear, and $ u_{n+1} -u_n - hf(t_{n+1},u_{n+1}) = 0$ is a nonlinear equation. We can therefore use the techniques we learned in chapter 2 to solve for $u_{n+1}$.\n",
        "\n",
        "Since the forward Euler equation gives $u_{n+1}$ as an explicit function of $u_n$ and $t_n$, and the backward Euler equation gives $u_{n+1}$ as an implicit function of $t_{n+1}$, $u_n$ and $u_{n+1}$ itself. For this reason, the forward Euler method is sometimes called the **explicit Euler method** and backward Euler is called the **implicit Euler method**.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u1Q7jiy5Xs0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Forward Euler\n",
        "%%writefile fwd_euler.m\n",
        "\n",
        "function y = fwd_euler(t0,T,y0,f,N)\n",
        "  % ==============================\n",
        "  % FORWARD EULER METHOD SOLVING\n",
        "  % CAUCHY PROBLEM y' = f(t,y)\n",
        "  % ON [t0,T] with y(0) = y0.\n",
        "  % N IS THE NUMBER OF NODES.\n",
        "  % ==============================\n",
        "  y = zeros(N,1); y(1)=y0; h = (T-t0)/(N-1);\n",
        "  nodes = t0:h:T;\n",
        "  for k = 2:N\n",
        "    yprev = y(k-1);\n",
        "    y(k) = yprev + h * f(nodes(k-1),yprev);\n",
        "  end"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KFvu65UrsLC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Backward Euler\n",
        "%%writefile bck_euler.m\n",
        "\n",
        "function y = bck_euler(t0,T,y0,f,N)\n",
        "  % ==============================\n",
        "  % BACKWARD EULER METHOD SOLVING\n",
        "  % CAUCHY PROBLEM y' = f(t,y)\n",
        "  % ON [t0,T] with y(0) = y0.\n",
        "  % N IS THE NUMBER OF NODES.\n",
        "  % ==============================\n",
        "  y = zeros(N,1); y(1)=y0; h = (T-t0)/(N-1);\n",
        "  nodes = t0:h:T;\n",
        "  for k = 2:N\n",
        "    yprev = y(k-1);\n",
        "    euler_fun = @(u) u - yprev - h * f(nodes(k),u);\n",
        "    y(k) = fsolve(euler_fun,yprev);\n",
        "  end"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UPRE2cQ_yy_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Euler methods example\n",
        "%%writefile euler_example.m\n",
        "\n",
        "f = @(t,y) cos(2*y);\n",
        "y_true = @(t) 0.5*asin( (e.^(4*t) - 1)./(e.^(4*t)+1) );\n",
        "t = linspace(0,1);\n",
        "\n",
        "N = 20; t0 = 0; T = 1; nodes = t0:(T-t0)/(N-1):T;\n",
        "y_fe = fwd_euler(0,1,0,f,N);\n",
        "y_be = bck_euler(0,1,0,f,N);\n",
        "\n",
        "fe_err = max(abs(y_fe' - y_true(nodes)))\n",
        "be_err = max(abs(y_be' - y_true(nodes)))\n",
        "\n",
        "% COPY INTO M FILE TO PLOT SOLUTIONS\n",
        "%figure(1), hold on, grid on\n",
        "%plot(t,y_true(t),'linewidth',1.5,'r--');\n",
        "%plot(nodes,y_fe,'linewidth',1.5,'b-*');"
      ],
      "metadata": {
        "id": "HjFV2F0lrSbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!octave -W euler_example.m"
      ],
      "metadata": {
        "id": "Qgn8KBQFxY2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of Euler Methods\n",
        "\n",
        "A numerical method **converges** if for each $n=0,...,N_h$,\n",
        "\n",
        "$$ |y_n - u_n|= \\mathcal{O}(h).$$\n",
        "\n",
        "Thus, as we add more or more nodes, our approximations at the nodes get better and better. We say that the method converges with order $p$ if  \n",
        "\n",
        "$$ |y_n - u_n|= \\mathcal{O}(h^p).$$\n",
        "\n",
        "The goal now is the show that the Euler methods converge with order 1. Precisely, we'll show via a standard argument that $e_n = y_n-u_n$ satisfies\n",
        "\n",
        "$$ |e_n| \\leq \\dfrac{e^{L(t_n-t_0)}-1}{L}\\dfrac{M}{2}h$$\n",
        "\n",
        "for the *forward Euler method*, where $L$ is the Lipschitz constant from the Existence and Uniqueness theorem and $M = \\max_{[t_0,T]} |y''|.$\n",
        "\n",
        "We first define an important quantity in the numerical solution of ODEs called the **local truncation error**.\n",
        "\n",
        "Denoted $\\tau_n(h)$, the local truncation error at the $n$th node for the forward Euler method is\n",
        "\n",
        "$$ \\tau_n(h) := \\dfrac{y_n - y_{n-1}}{h} - f(t_{n-1},y_{n-1}).$$\n",
        "\n",
        "We can obtain another expresion for $\\tau_n(h)$ using our favorite trick: Taylor expansion.\n",
        "\n",
        "$$ y_n = y_{n-1} + hf(t_{n-1},y_{n-1}) + y''(\\eta)\\dfrac{h^2}{2},$$\n",
        "\n",
        "where, as usual, $\\eta$ is some number between $t_{n-1}$ and $t_n$. Isolating the last term on the right-hand-side and dividing by $h$ gives us\n",
        "\n",
        "$$ \\tau_n(h) = \\dfrac{y_n - y_{n-1}}{h} - f(t_{n-1},y_{n-1}) = y''(\\eta)\\dfrac{h}{2}.$$\n",
        "\n",
        "The local truncation error $\\tau_n(h)$ is essentially a measure of how well our scheme approximates the derivative at each node. If $\\tau(h):=\\max_n |\\tau_n(h)|=\\frac{h}{2}\\max_{[t_0,T]}|y''|\\to 0$ as $h\\to 0$, we say that our method is **consistent**. It turns out that consistency is a necessary condition for convergence.  \n",
        "\n",
        "Now let's consider $|e_n|=|y_n-u_n|$ for the forwrad Euler method, i.e., where $u_n = u_{n-1} + hf(t_{n-1},u_{n-1})$.\n",
        "From our local truncation analysis, we have that\n",
        "$y_n = y_{n-1} + hf(t_{n-1},y_{n-1})+h\\tau_n(h)$. Using this, the triangle inequality, and replacing $u_n$ with $u_{n-1}+hf(t_{n-1},u_{n-1})$, we get\n",
        "\n",
        "$$ |e_n| \\leq |e_{n-1}| + h|f(t_{n-1},y_{n-1})-f(t_{n-1},u_{n-1})|+h|\\tau_n(h)|.$$\n",
        "\n",
        "Since we assume that $f(t,y)$ is Lipschitz with respect to $y$, it follows that\n",
        "\n",
        "$$ |e_n| \\leq (1 + hL)|e_{n-1}|+h|\\tau_n(h)|.$$\n",
        "\n",
        "Let $r = 1+hL$, and repeatedly applying this bound to $e_{n-1}$, $e_{n-2}$, all the way to $e_0$ yields\n",
        "\n",
        "$$ |e_n| \\leq r^2|e_{n-1}| + rh|\\tau_{n-1}(h)| + h|\\tau_n(h)| \\leq \\cdots\\leq r^n|e_0|+[r^{n-1}+r^{n-2}+\\cdots+1]h\\tau(h) = [r^{n-1}+r^{n-2}+\\cdots+1]h\\tau(h)$$\n",
        "\n",
        "since $|e_0|=0$.f The sum in the brackets above is a geometric sum:\n",
        "\n",
        "$$ \\sum_{k=0}^{n-1} r^k = \\dfrac{r^{n}-1}{r-1} = \\dfrac{(1+hL)^n - 1}{hL}.$$\n",
        "\n",
        "Thus\n",
        "\n",
        "$$ |e_n| \\leq \\dfrac{(1+hL)^n - 1}{L}\\tau(h).$$\n",
        "\n",
        "Now we'll use an interesting inequality. For any real number $x$, it can be shown that\n",
        "\n",
        "$$ e^x \\geq x+1.$$\n",
        "\n",
        "There are many ways to prove this fact. An interesting discussion of some of these proofs can be found [here](https://math.stackexchange.com/questions/504663/simplest-or-nicest-proof-that-1x-le-ex). Setting $x = hL$, this inequality implies that\n",
        "\n",
        "$$ |e_n|\\leq \\dfrac{e^{nhL}-1}{L}\\dfrac{M}{2}h = \\dfrac{e^{L(t_n-t_0)}-1}{L}\\dfrac{M}{2}h, \\hspace{0.5em} n = 0,1,...,N_h. $$\n",
        "\n",
        "where $M = \\max_{[t_0,T]} |y''|$.\n",
        "\n",
        "The backward Euler method can be analyzed similarly, or using the alternate analysis method discussed below."
      ],
      "metadata": {
        "id": "R3UKyODCpKqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crank-Nicolson\n",
        "\n",
        "In the example above, we saw that both forward Euler and backward Euler work reasonably well in that they yield solutions that pass the eyeball test. We also noticed that forward Euler seemed to lie above the true solution, while the backward Euler lay below. This suggests that we may get a better method by averaging the forward Euler and backward Euler steps. Doing this yields the **Crank-Nicolson method**. Let $f_n = f(t_n,u_n)$. Then define\n",
        "\n",
        "$$ u_{n+1} = u_n + \\dfrac{h}{2}\\left(f_n+f_{n+1}\\right),\\hspace{0.5em} n=0,...,N_h.$$\n",
        "\n",
        "Like with backward Euler method, we'll need to solve the (possibly nonlinear) equation\n",
        "\n",
        "$$ u_{n+1} - u_n + \\dfrac{h}{2}\\left(f_n+f_{n+1}\\right) = 0 $$\n",
        "\n",
        "for $u_{n+1}$ at each step. This is not a lateral move though, since it turns out that Crank-Nicolson converges with **order 2**. We can show this using the same ideas we used for forward Euler, but we can also use a result from Chapter 4. Here, we'll just show that Crank-Nicolson is consistent of order 2.\n",
        "\n",
        "By integrating both sides of $y'(t) = f(t,y)$ over $[t_{n-1},t_n]$ and applying the Fundamental Theorem of Calculus, we get\n",
        "\n",
        "$$ y_n = y_{n-1} + \\int_{t_{n-1}}^{t_n} f(s,y(s))\\,ds.$$\n",
        "\n",
        "Let's now approximate the integral on the left-hand-side by the *trapezoid rule*, but using $u_n$ and $u_{n-1}$ in place of $y_n$ and $y_{n-1}$. This yields\n",
        "\n",
        "$$ y_n\\approx u_n = u_{n-1} + \\dfrac{h}{2}\\left(f_{n-1}+f_n\\right),$$\n",
        "\n",
        "which is precisely Crank-Nicolson! If we didn't use $u_n$ and $u_{n-1}$ above, we obtain precisely the trapezoid rule applied to $y'(s) = f(s,y(s))$ over $[t_{n-1},t_n]$. Thus\n",
        "\n",
        "$$ y_n = y_{n-1} + \\dfrac{h}{2}\\left(f(t_{n-1},y_{n-1})+f(t_n,y_n) \\right) - \\dfrac{h^3}{12}y'''(\\eta),$$\n",
        "\n",
        "where $\\eta$ is some number between $t_{n-1}$ and $t_n$. The local truncation error for Crank-Nicolson is therefore $h^2y'''(\\eta)/12$, which implies that Crank-Nicolson is consistent with order 2.\n",
        "\n",
        "Let's revisit the example from earlier and see how Crank-Nicolson compares with the Euler methods.\n"
      ],
      "metadata": {
        "id": "u3Hjuf95wDtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Crank-Nicolson\n",
        "%%writefile crank_nicolson.m\n",
        "  function y = crank_nicolson(t0,T,y0,f,N)\n",
        "    % ==============================\n",
        "    % CRANK-NICOLSON METHOD SOLVING\n",
        "    % CAUCHY PROBLEM y' = f(t,y)\n",
        "    % ON [t0,T] with y(0) = y0.\n",
        "    % N IS THE NUMBER OF NODES.\n",
        "    % ==============================\n",
        "    y = zeros(N,1); y(1)=y0; h = (T-t0)/(N-1);\n",
        "    nodes = t0:h:T;\n",
        "    for k = 2:N\n",
        "      yprev = y(k-1);\n",
        "      euler_fun = @(u) u - yprev - 0.5*h*( f(nodes(k),u)+f(nodes(k-1),yprev) );\n",
        "      y(k) = fsolve(euler_fun,yprev);\n",
        "    end\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sogTXZ0k239b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Crank-Nicolson example\n",
        "%%writefile crank_nicolson_example.m\n",
        "\n",
        "f = @(t,y) cos(2*y);\n",
        "y_true = @(t) 0.5*asin( (e.^(4*t) - 1)./(e.^(4*t)+1) );\n",
        "t = linspace(0,1);\n",
        "\n",
        "N = 160; t0 = 0; T = 1; nodes = t0:(T-t0)/(N-1):T;\n",
        "y_fe = fwd_euler(0,1,0,f,N);\n",
        "y_be = bck_euler(0,1,0,f,N);\n",
        "y_cn = crank_nicolson(0,1,0,f,N);\n",
        "\n",
        "fe_err = max(abs(y_fe' - y_true(nodes)))\n",
        "be_err = max(abs(y_be' - y_true(nodes)))\n",
        "cn_err = max(abs(y_cn' - y_true(nodes)))\n",
        "\n",
        "% COPY INTO M FILE TO PLOT SOLUTIONS\n",
        "%figure(1), hold on, grid on\n",
        "%plot(t,y_true(t),'linewidth',1.5,'r--');\n",
        "%plot(nodes,y_fe,'linewidth',1.5,'b-*');"
      ],
      "metadata": {
        "cellView": "form",
        "id": "F9h_l30v3rBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!octave -W crank_nicolson_example.m"
      ],
      "metadata": {
        "id": "X4VHJsia35L2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}